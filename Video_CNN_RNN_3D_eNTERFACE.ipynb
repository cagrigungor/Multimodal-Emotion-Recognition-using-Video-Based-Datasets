{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Video_CNN_RNN_3D_eNTERFACE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2Ov46NsAhwF",
        "colab_type": "code",
        "outputId": "1fd8bf4f-6191-44a7-9198-3519f46fd84f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import re\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import warnings\n",
        "import math\n",
        "warnings.filterwarnings('ignore')\n",
        "from google.colab import drive \n",
        "drive.mount('/mntDrive')"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /mntDrive; to attempt to forcibly remount, call drive.mount(\"/mntDrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQpoAIIkcTg8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eNTERFACE_PATH = \"/mntDrive/My Drive/Data/eNTERFACE\"\n",
        "pretrain_path = \"/mntDrive/My Drive/Data/r3d50_KMS_200ep.pth\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k54tp7ILJ_eF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def sorted_alphanumeric(data):\n",
        "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
        "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
        "    return sorted(data, key=alphanum_key)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKSqGY-cAy45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, image_paths,transform,transform2):\n",
        "        self.image_paths = image_paths\n",
        "        self.paths = []\n",
        "        self.transform = transform\n",
        "        self.transform2 = transform2\n",
        "        files = os.listdir(self.image_paths)\n",
        "        tot_num = 0\n",
        "        n = 0\n",
        "\n",
        "        for file in files:\n",
        "            integers = re.findall(r'\\d+', file)\n",
        "            index = int(integers[0]) \n",
        "          \n",
        "            \n",
        "            if index < 32:\n",
        "              self.paths.append(file)\n",
        "         \n",
        "        self.paths = sorted_alphanumeric(self.paths)\n",
        "        #random.shuffle(self.paths)\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        path = self.paths[index]\n",
        "        dict_data = np.load(self.image_paths+\"/\"+path)\n",
        "        data = dict_data['arr_0']\n",
        "        data = data[0]\n",
        "        images = []\n",
        "        images2 = []\n",
        "\n",
        "        outdatasize = 16.0\n",
        "        datalen = len(data)\n",
        "        for i in range(int(outdatasize)):\n",
        "          index = math.floor(datalen/outdatasize*(i))\n",
        "  \n",
        "          inx = data[index]\n",
        "          img = Image.fromarray(inx, 'RGB')\n",
        "          \n",
        "          if self.transform:\n",
        "                temp = self.transform(img)\n",
        "\n",
        "          if self.transform2:\n",
        "                temp2 = self.transform2(img)\n",
        "\n",
        "          images.append(temp)\n",
        "          images2.append(temp2)\n",
        "        x = np.stack(images)\n",
        "        x2 = np.stack(images2)\n",
        "        #x = torch.from_numpy(data).float().to(device)\n",
        "      \n",
        "        if \"an\" in path:\n",
        "            y = torch.tensor(0, dtype=torch.long)\n",
        "        elif \"di\" in path:\n",
        "            y = torch.tensor(1, dtype=torch.long)\n",
        "        elif \"fe\" in path:\n",
        "            y = torch.tensor(2, dtype=torch.long)\n",
        "        elif \"ha\" in path:\n",
        "            y = torch.tensor(3, dtype=torch.long)\n",
        "        elif \"sa\" in path:\n",
        "            y = torch.tensor(4, dtype=torch.long)\n",
        "        elif \"su\" in path:\n",
        "            y = torch.tensor(5, dtype=torch.long)\n",
        "        return x,x2,y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def l(self):\n",
        "        return len(self.paths)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEW6VMVCGVxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ValDataset(Dataset):\n",
        "    def __init__(self, image_paths,transform,transform2):\n",
        "        self.image_paths = image_paths\n",
        "        self.paths = []\n",
        "        self.transform = transform\n",
        "        self.transform2 = transform2\n",
        "        files = os.listdir(self.image_paths)\n",
        "        tot_num = 0\n",
        "        n = 0\n",
        "\n",
        "        for file in files:\n",
        "            integers = re.findall(r'\\d+', file)\n",
        "            index = int(integers[0]) \n",
        "\n",
        "            if index > 23:\n",
        "                self.paths.append(file)\n",
        "                \n",
        "        self.paths = sorted_alphanumeric(self.paths)\n",
        "    def __getitem__(self,index):\n",
        "        path = self.paths[index]\n",
        "        dict_data = np.load(self.image_paths+\"/\"+path)\n",
        "        data = dict_data['arr_0']\n",
        "        data = data[0]\n",
        "        images = []\n",
        "        images2 = []\n",
        "\n",
        "        outdatasize = 16.0\n",
        "        datalen = len(data)\n",
        "        for i in range(int(outdatasize)):\n",
        "          index = math.floor(datalen/outdatasize*(i))\n",
        "  \n",
        "          inx = data[index]\n",
        "          img = Image.fromarray(inx, 'RGB')\n",
        "          \n",
        "          if self.transform:\n",
        "                temp = self.transform(img)\n",
        "\n",
        "          if self.transform2:\n",
        "                temp2 = self.transform2(img)\n",
        "\n",
        "          images.append(temp)\n",
        "          images2.append(temp2)\n",
        "        x = np.stack(images)\n",
        "        x2 = np.stack(images2)\n",
        "        #x = torch.from_numpy(data).float().to(device)\n",
        "      \n",
        "        if \"an\" in path:\n",
        "            y = torch.tensor(0, dtype=torch.long)\n",
        "        elif \"di\" in path:\n",
        "            y = torch.tensor(1, dtype=torch.long)\n",
        "        elif \"fe\" in path:\n",
        "            y = torch.tensor(2, dtype=torch.long)\n",
        "        elif \"ha\" in path:\n",
        "            y = torch.tensor(3, dtype=torch.long)\n",
        "        elif \"sa\" in path:\n",
        "            y = torch.tensor(4, dtype=torch.long)\n",
        "        elif \"su\" in path:\n",
        "            y = torch.tensor(5, dtype=torch.long)\n",
        "        return x,x2,y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "    def l(self):\n",
        "        return len(self.paths)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajH8tYXvG8Hz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, image_paths,transform,transform2):\n",
        "        self.image_paths = image_paths\n",
        "        self.paths = []\n",
        "        self.transform = transform\n",
        "        self.transform2 = transform2\n",
        "        files = os.listdir(self.image_paths)\n",
        "        tot_num = 0\n",
        "        n = 0\n",
        "\n",
        "        for file in files:\n",
        "            integers = re.findall(r'\\d+', file)\n",
        "            index = int(integers[0]) \n",
        "  \n",
        "            if index > 22:\n",
        "              if index < 37:\n",
        "                self.paths.append(file)\n",
        "            \n",
        "        self.paths = sorted_alphanumeric(self.paths)\n",
        "        #random.shuffle(self.paths)\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        path = self.paths[index]\n",
        "        dict_data = np.load(self.image_paths+\"/\"+path)\n",
        "        data = dict_data['arr_0']\n",
        "        data = data[0]\n",
        "        images = []\n",
        "        images2 = []\n",
        "\n",
        "        outdatasize = 16.0\n",
        "        datalen = len(data)\n",
        "        for i in range(int(outdatasize)):\n",
        "          index = math.floor(datalen/outdatasize*(i))\n",
        "  \n",
        "          inx = data[index]\n",
        "          img = Image.fromarray(inx, 'RGB')\n",
        "          \n",
        "          if self.transform:\n",
        "                temp = self.transform(img)\n",
        "\n",
        "          if self.transform2:\n",
        "                temp2 = self.transform2(img)\n",
        "\n",
        "          images.append(temp)\n",
        "          images2.append(temp2)\n",
        "        x = np.stack(images)\n",
        "        x2 = np.stack(images2)\n",
        "        #x = torch.from_numpy(data).float().to(device)\n",
        "      \n",
        "        if \"an\" in path:\n",
        "            y = torch.tensor(0, dtype=torch.long)\n",
        "        elif \"di\" in path:\n",
        "            y = torch.tensor(1, dtype=torch.long)\n",
        "        elif \"fe\" in path:\n",
        "            y = torch.tensor(2, dtype=torch.long)\n",
        "        elif \"ha\" in path:\n",
        "            y = torch.tensor(3, dtype=torch.long)\n",
        "        elif \"sa\" in path:\n",
        "            y = torch.tensor(4, dtype=torch.long)\n",
        "        elif \"su\" in path:\n",
        "            y = torch.tensor(5, dtype=torch.long)\n",
        "        return x,x2,y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "    def l(self):\n",
        "        return len(self.paths)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJYDE-eZcxPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files = os.listdir(eNTERFACE_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cfMKv1lBt2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128,171)),\n",
        "    transforms.CenterCrop(112),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "transform2 = transforms.Compose([\n",
        "    transforms.Resize(226),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "train = TrainDataset(eNTERFACE_PATH,transform,transform2)\n",
        "train_loader = DataLoader(train,batch_size=1, shuffle=True)\n",
        "val = ValDataset(eNTERFACE_PATH,transform,transform2)\n",
        "val_loader = DataLoader(val,batch_size=1, shuffle=True)\n",
        "test = TestDataset(eNTERFACE_PATH,transform,transform2)\n",
        "test_loader = DataLoader(test,batch_size=1, shuffle=True)\n",
        "train_count = train.l()\n",
        "valid_count = val.l()\n",
        "test_count = test.l()\n",
        "\n",
        "a = 0\n",
        "b = 0\n",
        "\n",
        "#for data,data2, target in train_loader:\n",
        "#    print(data.shape,data2.shape,target[0])\n",
        "    \n",
        "    #if(target[0] == 0):\n",
        "    #  a = a + 1\n",
        "    #if(target[0] == 1):\n",
        "    #  b = b + 1\n",
        "    #print(a,b)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VuDBkpe9bV9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "b9bc844b-66e6-4669-ec59-020af7c74580"
      },
      "source": [
        "max_epoch = 50\n",
        "batch_size = 1\n",
        "learning_rate = 0.001\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "!pip install GPUtil\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: GPUtil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Gen RAM Free: 24.7 GB  |     Proc size: 3.5 GB\n",
            "GPU RAM Free: 13347MB | Used: 2933MB | Util  18% | Total     16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTjJ3b4ZI-V3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "from functools import partial\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def get_inplanes():\n",
        "    return [64, 128, 256, 512]\n",
        "\n",
        "\n",
        "def conv3x3x3(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv3d(in_planes,\n",
        "                     out_planes,\n",
        "                     kernel_size=3,\n",
        "                     stride=stride,\n",
        "                     padding=1,\n",
        "                     bias=False)\n",
        "\n",
        "\n",
        "def conv1x1x1(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv3d(in_planes,\n",
        "                     out_planes,\n",
        "                     kernel_size=1,\n",
        "                     stride=stride,\n",
        "                     bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, downsample=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = conv3x3x3(in_planes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm3d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm3d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, downsample=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = conv1x1x1(in_planes, planes)\n",
        "        self.bn1 = nn.BatchNorm3d(planes)\n",
        "        self.conv2 = conv3x3x3(planes, planes, stride)\n",
        "        self.bn2 = nn.BatchNorm3d(planes)\n",
        "        self.conv3 = conv1x1x1(planes, planes * self.expansion)\n",
        "        self.bn3 = nn.BatchNorm3d(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 block,\n",
        "                 layers,\n",
        "                 block_inplanes,\n",
        "                 n_input_channels=3,\n",
        "                 conv1_t_size=7,\n",
        "                 conv1_t_stride=1,\n",
        "                 no_max_pool=False,\n",
        "                 shortcut_type='B',\n",
        "                 widen_factor=1.0,\n",
        "                 n_classes=400):\n",
        "        super().__init__()\n",
        "\n",
        "        block_inplanes = [int(x * widen_factor) for x in block_inplanes]\n",
        "\n",
        "        self.in_planes = block_inplanes[0]\n",
        "        self.no_max_pool = no_max_pool\n",
        "\n",
        "        self.conv1 = nn.Conv3d(n_input_channels,\n",
        "                               self.in_planes,\n",
        "                               kernel_size=(conv1_t_size, 7, 7),\n",
        "                               stride=(conv1_t_stride, 2, 2),\n",
        "                               padding=(conv1_t_size // 2, 3, 3),\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm3d(self.in_planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, block_inplanes[0], layers[0],\n",
        "                                       shortcut_type)\n",
        "        self.layer2 = self._make_layer(block,\n",
        "                                       block_inplanes[1],\n",
        "                                       layers[1],\n",
        "                                       shortcut_type,\n",
        "                                       stride=2)\n",
        "        self.layer3 = self._make_layer(block,\n",
        "                                       block_inplanes[2],\n",
        "                                       layers[2],\n",
        "                                       shortcut_type,\n",
        "                                       stride=2)\n",
        "        self.layer4 = self._make_layer(block,\n",
        "                                       block_inplanes[3],\n",
        "                                       layers[3],\n",
        "                                       shortcut_type,\n",
        "                                       stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
        "        self.fc = nn.Linear(block_inplanes[3] * block.expansion, n_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv3d):\n",
        "                nn.init.kaiming_normal_(m.weight,\n",
        "                                        mode='fan_out',\n",
        "                                        nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm3d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _downsample_basic_block(self, x, planes, stride):\n",
        "        out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n",
        "        zero_pads = torch.zeros(out.size(0), planes - out.size(1), out.size(2),\n",
        "                                out.size(3), out.size(4))\n",
        "        if isinstance(out.data, torch.cuda.FloatTensor):\n",
        "            zero_pads = zero_pads.cuda()\n",
        "\n",
        "        out = torch.cat([out.data, zero_pads], dim=1)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, shortcut_type, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_planes != planes * block.expansion:\n",
        "            if shortcut_type == 'A':\n",
        "                downsample = partial(self._downsample_basic_block,\n",
        "                                     planes=planes * block.expansion,\n",
        "                                     stride=stride)\n",
        "            else:\n",
        "                downsample = nn.Sequential(\n",
        "                    conv1x1x1(self.in_planes, planes * block.expansion, stride),\n",
        "                    nn.BatchNorm3d(planes * block.expansion))\n",
        "\n",
        "        layers = []\n",
        "        layers.append(\n",
        "            block(in_planes=self.in_planes,\n",
        "                  planes=planes,\n",
        "                  stride=stride,\n",
        "                  downsample=downsample))\n",
        "        self.in_planes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.in_planes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        if not self.no_max_pool:\n",
        "            x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def generate_model(model_depth, **kwargs):\n",
        "    assert model_depth in [10, 18, 34, 50, 101, 152, 200]\n",
        "\n",
        "    if model_depth == 10:\n",
        "        model = ResNet(BasicBlock, [1, 1, 1, 1], get_inplanes(), **kwargs)\n",
        "    elif model_depth == 18:\n",
        "        model = ResNet(BasicBlock, [2, 2, 2, 2], get_inplanes(), **kwargs)\n",
        "    elif model_depth == 34:\n",
        "        model = ResNet(BasicBlock, [3, 4, 6, 3], get_inplanes(), **kwargs)\n",
        "    elif model_depth == 50:\n",
        "        model = ResNet(Bottleneck, [3, 4, 6, 3], get_inplanes(), **kwargs)\n",
        "    elif model_depth == 101:\n",
        "        model = ResNet(Bottleneck, [3, 4, 23, 3], get_inplanes(), **kwargs)\n",
        "    elif model_depth == 152:\n",
        "        model = ResNet(Bottleneck, [3, 8, 36, 3], get_inplanes(), **kwargs)\n",
        "    elif model_depth == 200:\n",
        "        model = ResNet(Bottleneck, [3, 24, 36, 3], get_inplanes(), **kwargs)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izzAEN7L9kY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as weight_init\n",
        "class ConvNet(nn.Module):\n",
        "    \n",
        "    def __init__(self,resnet_3D,resnet34): \n",
        "    # you can add any additional parameters you want \n",
        "    # TODO:\n",
        "    # You should create your neural network here\n",
        "        super(ConvNet,self).__init__()\n",
        "      # convolutional layer\n",
        "        self.resnet_3D = resnet_3D\n",
        "        self.resnet34 = resnet34\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_size=256, hidden_size=256, num_layers=1,  bidirectional=False)\n",
        "        for name, param in self.lstm.named_parameters(): \n",
        "          if 'bias' in name:\n",
        "            weight_init.constant(param, 0.0)\n",
        "          elif 'weight' in name:\n",
        "            weight_init.xavier_uniform(param);\n",
        "\n",
        "        self.lstm2 = nn.LSTM(input_size=256, hidden_size=512, num_layers=1,  bidirectional=False)\n",
        "        for name, param in self.lstm2.named_parameters(): \n",
        "          if 'bias' in name:\n",
        "            weight_init.constant(param, 0.0)\n",
        "          elif 'weight' in name:\n",
        "            weight_init.xavier_uniform(param);\n",
        "        #self.fc_lstm=nn.Sequential(\n",
        "        #    self.lstm)\n",
        "        \n",
        "      # fully connected layers\n",
        "        self.fc1 = nn.Linear(1000, 256)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, 6)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.att = nn.Parameter(torch.ones(1024))\n",
        "    \n",
        "          \n",
        "    def forward(self, X,X2): \n",
        "    # you can add any additional parameters you want\n",
        "    # TODO:\n",
        "    # Forward propagation implementation should be here\n",
        "        #X = X[None,:,:,:]\n",
        "    \n",
        "        X = self.resnet_3D(X)\n",
        "        X2 = self.resnet34(X2)\n",
        "     \n",
        "        X2 = self.relu(X2)\n",
        "        X2 = self.fc1(X2)\n",
        "\n",
        "        X2 = X2[:,None,:]\n",
        "        X2, (h,c) = self.lstm(X2)\n",
        "        X2, (h,c) = self.lstm2(X2)\n",
        "        X2 = X2[-1]\n",
        "       \n",
        "        fusion = torch.cat((X, X2), dim=1)\n",
        "        fusion = self.att * fusion\n",
        "        \n",
        "        fusion = self.fc2(fusion)\n",
        "        fusion = self.relu(fusion)\n",
        "        fusion = self.fc3(fusion)\n",
        "        return fusion"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0LNMkwha8Js",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(criterion, optimizer, model):\n",
        "    train_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "    \n",
        "    batch_acc = []\n",
        "    batch_loss = []\n",
        "    num = 0\n",
        "    # training the model with the train dataset.\n",
        "    for train_images,train_images2, train_labels in train_loader:\n",
        "        train_images = train_images.to( device ,dtype=torch.float)\n",
        "        train_images2 = train_images2.to( device ,dtype=torch.float)\n",
        "        train_labels = train_labels.to( device ,dtype=torch.float) \n",
        "\n",
        "      \n",
        "        train_labels_head = model.forward(train_images.permute(0,2,1,3,4),train_images2[0])\n",
        "\n",
        "        loss = criterion(train_labels_head, train_labels.long())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()  \n",
        "\n",
        "        predictions = torch.max( train_labels_head , 1)[1] \n",
        "      \n",
        "        acurracy = torch.sum( predictions == train_labels )\n",
        "\n",
        "        accur_save = float(acurracy.float())/1\n",
        "        loss_save= float(loss.item())/1\n",
        "\n",
        "        train_acc += acurracy \n",
        "        train_loss += loss.item()\n",
        "        num = num + 1\n",
        "        if num % 1000 == 0:\n",
        "          print(num,train_acc/num)\n",
        "\n",
        "        train_acc_print = accur_save\n",
        "        batch_acc.append(train_acc_print)\n",
        "        train_loss_print = loss_save\n",
        "        batch_loss.append(train_loss_print)\n",
        "\n",
        "    return train_loss, train_acc,batch_acc,batch_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPsenUzy9wWp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate_model(criterion, model):\n",
        "    valid_loss = 0.0\n",
        "    valid_acc  = 0.0\n",
        "    valid_labels_tot = []\n",
        "    pred = []\n",
        "    # testing the current model within the current epoch.\n",
        "    for valid_images,valid_images2, valid_labels in val_loader:\n",
        "        #GPUs = GPU.getGPUs()\n",
        "        # XXX: only one GPU on Colab and isn’t guaranteed\n",
        "        #gpu = GPUs[0]\n",
        "\n",
        "        #process = psutil.Process(os.getpid())\n",
        "        acurracy,loss,predictions = step(valid_images,valid_images2,valid_labels)\n",
        "        # calculating acurracy for the cur-\n",
        "        # rent batch for the test dataset.\n",
        "        \n",
        "    \n",
        "        # summing test acurracy and \n",
        "        # loss wit the remaining batches.\n",
        "        valid_acc  += acurracy \n",
        "        valid_loss += loss.item()\n",
        "        valid_labels_tot.append(valid_labels)\n",
        "        pred.append(predictions)\n",
        "    return valid_loss, valid_acc,pred,valid_labels_tot\n",
        "def step(valid_images,valid_images2,valid_labels):\n",
        "  # registering test images and labels \n",
        "  # to device to benefit from GPU\n",
        "  valid_images = valid_images.to( device ,dtype=torch.float)\n",
        "  valid_images2 = valid_images2.to( device ,dtype=torch.float)\n",
        "  valid_labels = valid_labels.to( device ,dtype=torch.float) \n",
        "\n",
        "      \n",
        "  valid_labels_head = model.forward(valid_images.permute(0,2,1,3,4),valid_images2[0])\n",
        "  loss = criterion(valid_labels_head, valid_labels.long())\n",
        "  predictions = torch.max( valid_labels_head, 1)[1] \n",
        "  acurracy = torch.sum( predictions == valid_labels )\n",
        "  \n",
        "  return acurracy,loss,predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yldsa7VR9x43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(criterion, model):\n",
        "    test_loss = 0.0\n",
        "    test_acc  = 0.0\n",
        "    test_labels_tot = []\n",
        "    pred = []\n",
        "    i = 1\n",
        "    # testing the current model within the current epoch.\n",
        "    for test_images,test_images2, test_labels in val_loader:\n",
        "        \n",
        "     \n",
        "        test_images = test_images.to( device ,dtype=torch.float)\n",
        "        test_images2 = test_images2.to( device ,dtype=torch.float)\n",
        "        test_labels = test_labels.to( device ,dtype=torch.float) \n",
        "\n",
        "      \n",
        "        test_labels_head = model.forward(test_images.permute(0,2,1,3,4),test_images2[0])\n",
        "        loss = criterion(test_labels_head, test_labels.long())\n",
        "        predictions = torch.max( test_labels_head, 1)[1] \n",
        "        acurracy = torch.sum( predictions == test_labels )\n",
        "        i = i + 1\n",
        "        test_acc  += acurracy \n",
        "        print(test_acc/i)\n",
        "        test_loss += loss.item()\n",
        "        test_labels_tot.append(test_labels)\n",
        "        pred.append(predictions)\n",
        "    return test_loss, test_acc, pred, test_labels_tot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3x3gBXF9mkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.init as weight_init\n",
        "\n",
        "resnet_3D = generate_model(50,n_classes=1139)\n",
        "print('loading pretrained model {}'.format(pretrain_path))\n",
        "pretrain = torch.load(pretrain_path, map_location='cpu')\n",
        "resnet_3D.load_state_dict(pretrain['state_dict'])\n",
        "\n",
        "i= 0\n",
        "for name,child in resnet_3D.named_children(): \n",
        "    for name2,param in child.named_parameters():\n",
        "      if i < 21:\n",
        "        print(name2,i)\n",
        "        i = i + 1\n",
        "        param.requires_grad = False\n",
        "\n",
        "#resnet_3D.relu = nn.ReLU(inplace=True)\n",
        "resnet_3D.fc = nn.Linear(2048, 512)\n",
        "#resnet.relu2 = nn.ReLU(inplace=True)\n",
        "\n",
        "resnet34 = torchvision.models.resnet34(pretrained=True)\n",
        "i = 0\n",
        "\n",
        "for name,child in resnet34.named_children(): \n",
        "    for name2,param in child.named_parameters():\n",
        "      if i < 15:\n",
        "        print(name2,i)\n",
        "        i = i + 1\n",
        "        param.requires_grad = False\n",
        "\n",
        "model = ConvNet(resnet_3D,resnet34).to(device)\n",
        "#model.load_state_dict(torch.load('/mntDrive/My Drive/Colab Notebooks/video_3D_CNN-RNN.pth'))\n",
        "\n",
        "#model = torch.load('/mntDrive/My Drive/Colab Notebooks/cont3.pth').to(device)\n",
        "\n",
        "print(model)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adamax(model.parameters(), lr=learning_rate) # you can play with momentum and weight_decay parameters as well\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "train_accurracies = []\n",
        "valid_accurracies = []\n",
        "batch_acc_tot  = []\n",
        "batch_loss_tot  = []\n",
        "best_acc = 0\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "    \n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "    valid_acc = 0.0\n",
        "  \n",
        "    # training the model with the train dataset.\n",
        "    train_loss, train_acc,batch_acc,batch_loss = train_model(criterion, optimizer, model)\n",
        "    batch_acc_tot.append(batch_acc)\n",
        "    batch_loss_tot.append(batch_loss)\n",
        "    # validating the current model within the current epoch.\n",
        "    with torch.no_grad():\n",
        "      valid_loss, valid_acc, predictions, valid_labels = validate_model(criterion, model)\n",
        "\n",
        "    valid_acc = float(valid_acc.float()) / valid_count\n",
        "    valid_accurracies.append( valid_acc )\n",
        "\n",
        "    pred = np.array([])\n",
        "    for i in predictions:\n",
        "      pred = np.concatenate((pred,i.cpu().detach().numpy()),axis=None)\n",
        "\n",
        "    labels = np.array([])\n",
        "    for i in valid_labels:\n",
        "      labels = np.concatenate((labels,i.cpu().detach().numpy()),axis=None)\n",
        "\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    import seaborn as sns\n",
        "    import matplotlib.pyplot as plt\n",
        "    cm = confusion_matrix(labels, pred)\n",
        "    cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis].astype('float')\n",
        "    \n",
        "    f, ax = plt.subplots(figsize = (10, 10))\n",
        "    sns.heatmap(cmn, annot = True, linewidths=1, linecolor='black', fmt='.2f', ax=ax)\n",
        "    plt.xlabel(\"Test Predictions\")\n",
        "    plt.ylabel(\"Test Labels\")\n",
        "    plt.show()\n",
        "\n",
        "    print(\"EPOCH --> \" + str(epoch + 1))\n",
        "    print(\"----------------------------------------------\") \n",
        "    train_acc = float(train_acc.float()) / train_count\n",
        "    train_accurracies.append( train_acc )\n",
        "    print(\"Train Acurracy: \" + str( float(train_acc) ))\n",
        "    \n",
        "    train_loss = train_loss / train_count\n",
        "    train_losses.append( train_loss )\n",
        "    print(\"Train Loss: \" + str(train_loss) + \"\\n\")\n",
        "\n",
        "    \n",
        "    print(\"Validation Acurracy: \" + str( float(valid_acc) ))    \n",
        "    \n",
        "    valid_loss = valid_loss / valid_count\n",
        "    valid_losses.append( valid_loss )\n",
        "    print(\"Validation Loss: \" + str(valid_loss))\n",
        "    print(\"----------------------------------------------\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}